{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Networks and Fake News Detection\n",
    "### Final Project for CSCI 381\n",
    "### Bless Bah Awazi, Kit Conklin, Munguldei Batsaikhan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sitting alone in the dark contemplating about the meaning of life, you suddenly realize that zebras don't have hands. Then, whose hands were those in the seemingly peaceful message? Surely, they didn't take a human hostage to Zearth?\n",
    "\n",
    "Your suspicions are confirmed when you recreate the received image and pass it into a more advanced Zebrese interpreter one of your UNCOOL colleagues had built. Turns out, in Zebrese, a heart is a signal for \"INVASION\"!\n",
    "\n",
    "Just then, the hip young intern your co-worker recently recruited to the team waltzes in wearing zebra-print pants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/z_intern.jpeg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You admire/question their bold fashion choice and head out for a much needed break. Outside, you witness a horrible sight:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/z_print2.jpeg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zebra prints everywhere! You have two horrible realizations: \n",
    "1. The model you built for distinguishing zebras is now near useless.\n",
    "2. Zebra prints are back in style. (Or, were they ever in style?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You run back into the office, grab the intern and press him as to where he got the idea to get such pants. He points to the latest volume of Zoomer Vogue — \"Zoomer Vogue interviewed Anna Wintour, and she said that zebra prints are the newest drip!\"\n",
    "\n",
    "You check the article, and it's clear that Zoomer Vogue is not a trustworthy source. A recent study you were reading on identifying fake news using Graph Neural Networks (GNNs) comes to your mind. You are ready to start building a GNN to detect fake zebra news with your UNCOOL colleagues, however, everyone is out of the office since the wrongly-interpreted peace reply was received.\n",
    "\n",
    "Now, it's only you and the intern. You ask him:\n",
    "\n",
    "\"Have you heard about Graph Neural Networks?\" <br>\n",
    "\"No. What is that?\" <br>\n",
    "\"It's a type of neural network-\" <br>\n",
    "\"Actually, before you explain any further, why should I care?\"\n",
    "\n",
    "It's going to be another long day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"<b>GNNs are neural networks that operate on graph data. And graphs are all around us since the world defines objects in relation to other objects! Think of how many systems you will be able to model with GNNs then! Currently, practical applications are seen in areas such as social networks, antibacterial discovery, cyber security, fake news detection, traffic prediction and recommendation systems</b>,\" you enthusiastically explain to the intern.\n",
    "\n",
    "The intern winces at the mention of a graph. So, you think a recap on graphs is in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap on Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What is a graph?</b>\n",
    "\n",
    "A graph is a data structure consisting of nodes and edges. The nodes store information about individual data points, such as news articles or zebras, allowing us to visualize each element in a dataset. The edges are lines drawn between a pair of nodes, connecting them and allowing us to visualize how individual data points interact with each other and the patterns by which they are interlinked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>How to use graphs to make predictions?</b>\n",
    "\n",
    "There are levels to which graph data can be used to predict information about a given problem:\n",
    "\n",
    "- <b>Graph-level tasks</b> involve analyzing the entire graph as input, assigning it a classification or label based on its overall shape and general characteristics. Then, we can make subsequent predictions about a specific property of the dataset based on the graph's properties. One example of a graph-level task is image classification: image data can be converted into a graph, which can be analyzed and labeled based on certain characteristics, allowing us to predict the contents of the image (i.e: whether or not it depicts a zebra) based on the graph’s classification (i.e: zebra or non-zebra). \n",
    "\n",
    "- <b>Node-level tasks</b> involve analyzing the nodes of a graph to predict the characteristics of individual data points and classify data points into groups based on predicted characteristics. An example of a node-level task may include a social network graph, where nodes represent individuals and edges represent relationships. A node-level task would be identifying social circles and classifying individuals based which circle they belong to\n",
    "predicting relationships between individuals in a social network graph, where nodes represent individuals and edges represent relationships. \n",
    "\n",
    "- <b>Edge-level tasks</b> involve analyzing the edges of a graph to predict how the nodes of a graph are connected. In the social network graph example, an edge-level task would be to predict relationships between individuals, identifying the likelihood that two individuals (nodes) would be related to each other (connected by an edge).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs as Matrices\n",
    "\n",
    "We now know that graphs can be very useful when working with unstructured data like social networks, and although we are very eager to make use of these to stop our zebra stripped foes we don't yet know how do to go about solving graph tasks with neural networks. The first step is to think about how we will represent graphs to be compatible with neural networks. \n",
    "\n",
    "<img src=\"img/Graph.png\" width=\"800\">\n",
    "\n",
    "Machine learning models typically take rectangular or grid-like arrays as input. So, it’s not immediately intuitive how to represent them in a format that is compatible with deep learning. However, representing a graph’s connectivity is more complicated. Perhaps the most obvious choice would be to use an adjacency matrix, since this is easily tensorisable. However, this representation has a few drawbacks. The first problem is that there are many adjacency matrices that can encode the same connectivity, and there is no guarantee that these different matrices would produce the same result in a deep neural network (that is to say, they are not permutation invariant). Three different adjacency matrix for the graph above are shown below.\n",
    "\n",
    "<img src=\"img/adj1.png\" width=\"300\">\n",
    "<img src=\"img/adj2.png\" width=\"300\">\n",
    "<img src=\"img/adj3.png\" width=\"300\">\n",
    "\n",
    "Another factor is that in real life graphs the number of nodes in a graph can be on the order of millions, and the number of edges per node can be highly variable. Often, this leads to very sparse adjacency matrices, which are space-inefficient.\n",
    "\n",
    "\n",
    "One elegant and memory-efficient way of representing sparse matrices is as adjacency lists. These describe the connectivity of edge $e_{k}$ between nodes $n_{i}$ and $n_{j}$ as a tuple (i,j) in the k-th entry of an adjacency list. Since we expect the number of edges to be much lower than the number of entries for an adjacency matrix ($n^{2}$ nodes), we avoid computation and storage on the disconnected parts of the graph.\n",
    "\n",
    "<img src=\"img/img3.jpg\" width=\"500\">\n",
    "\n",
    "We can then store the information in a nodes tensor and a connectivity tensor as shown below. \n",
    "\n",
    "Nodes tensor: `[1, 2, 3, 4, 5, 6, 7, 8]`\n",
    "Connectivity tensor: `[[2, 1], [3, 1], [5, 4], [7, 3], [8, 4], [8, 5], [8, 6]]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Simple GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our input is permutation invariant, we can start using GNNs to solve graph prediction tasks.\n",
    "\n",
    "We may think of <b>GNNs as a function that acts on all attributes of the graph (nodes, edges, global-context) such that it preserves graph symmetries (permutation invariances)</b>. So, the input of a GNN is a graph with information loaded into its nodes, edges and global-context; and the output is a graph with these transformed embeddings that retains the original connectivity structure. We may visualize a single layer of GNN as following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/simple_layer.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling in GNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we would like our model to be able to differentiate fake news (`\"False\"`) from real (`\"True\"`), let's focus on logistic regression to exploring pooling in GNNs.\n",
    "\n",
    "- <b>Prediction using self-information</b>: Given a graph that already contains information on nodes, edges and global context, we just apply a linear classifier (think `softmax`) to make a binary prediction on the respective element.\n",
    "  \n",
    "- <b>Prediction using others' information</b>: For example, what if we would like to make predictions on nodes, but the input graph only contains information in edges and not in nodes? In such cases, we need a way to collect information from the edges and give it to the nodes. We can do this by <b>pooling</b>, which proceeds in the following two steps for GNNs:\n",
    "  \n",
    "    1. For each element to be pooled, collect each of their embeddings and add them into a matrix.\n",
    "    2. The collected embeddings are then combined, usually via the sum operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/pooling.png\" width=\"300\" style=\"display=block; margin:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pooling can be performed not only from edges to nodes, but also to global embdeddings and vice versa. (Think submarines in CNNs!) Putting everything together, our simplified GNN network looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/simple_GNN.png\" width=\"800\" style=\"display=block; margin:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Remember</b> we don't use the connectivity of the graph at all inside the GNN layer. Each node is processed independently, as is each edge, as well as the global context. We only use connectivity when pooling information for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving Problems with GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import UPFD\n",
    "train_data = UPFD(root=\".\", name=\"gossipcop\", feature=\"content\", split=\"train\")\n",
    "test_data = UPFD(root=\".\", name=\"gossipcop\", feature=\"content\", split=\"test\")\n",
    "print(\"Train Samples: \", len(train_data))\n",
    "print(\"Test Samples: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id=1\n",
    "train_data[sample_id].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# From PyG utils\n",
    "def to_networkx(data, node_attrs=None, edge_attrs=None, to_undirected=False,\n",
    "                remove_self_loops=False):\n",
    "    if to_undirected:\n",
    "        G = nx.Graph()\n",
    "    else:\n",
    "        G = nx.DiGraph()\n",
    "    G.add_nodes_from(range(data.num_nodes))\n",
    "    node_attrs, edge_attrs = node_attrs or [], edge_attrs or []\n",
    "    values = {}\n",
    "    for key, item in data(*(node_attrs + edge_attrs)):\n",
    "        if torch.is_tensor(item):\n",
    "            values[key] = item.squeeze().tolist()\n",
    "        else:\n",
    "            values[key] = item\n",
    "        if isinstance(values[key], (list, tuple)) and len(values[key]) == 1:\n",
    "            values[key] = item[0]\n",
    "    for i, (u, v) in enumerate(data.edge_index.t().tolist()):\n",
    "        if to_undirected and v > u:\n",
    "            continue\n",
    "        if remove_self_loops and u == v:\n",
    "            continue\n",
    "        G.add_edge(u, v)\n",
    "        for key in edge_attrs:\n",
    "            G[u][v][key] = values[key][i]\n",
    "    for key in node_attrs:\n",
    "        for i, feat_dict in G.nodes(data=True):\n",
    "            feat_dict.update({key: values[key][i]})\n",
    "    return G\n",
    "\n",
    "nx.draw(to_networkx(train_data[sample_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data[sample_id].x.shape)\n",
    "train_data[sample_id].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "labels = [data.y.item() for i, data in enumerate(train_data)]\n",
    "df = pd.DataFrame(labels, columns=[\"Labels\"])\n",
    "df[\"Labels\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import global_max_pool as gmp\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.nn import Linear\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Graph Convolutions\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GATConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        # Readout\n",
    "        self.lin_news = Linear(in_channels, hidden_channels)\n",
    "        self.lin0 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin1 = Linear(2*hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Graph Convolutions\n",
    "        h = self.conv1(x, edge_index).relu()\n",
    "        h = self.conv2(h, edge_index).relu()\n",
    "        h = self.conv3(h, edge_index).relu()\n",
    "\n",
    "        # Pooling\n",
    "        h = gmp(h, batch)\n",
    "\n",
    "        # Readout\n",
    "        h = self.lin0(h).relu()\n",
    "\n",
    "        # According to UPFD paper: Include raw word2vec embeddings of news \n",
    "        # This is done per graph in the batch\n",
    "        root = (batch[1:] - batch[:-1]).nonzero(as_tuple=False).view(-1)\n",
    "        root = torch.cat([root.new_zeros(1), root + 1], dim=0)\n",
    "        # root is e.g. [   0,   14,   94,  171,  230,  302, ... ]\n",
    "        news = x[root]\n",
    "        news = self.lin_news(news).relu()\n",
    "        \n",
    "        out = self.lin1(torch.cat([h, news], dim=-1))\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "GNN(train_data.num_features, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GNN(train_data.num_features, 128, 1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "loss_fnc = torch.nn.BCELoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = loss_fnc(torch.reshape(out, (-1,)), data.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "@torch.no_grad()\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = loss_fnc(torch.reshape(out, (-1,)), data.y.float())\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        all_preds.append(torch.reshape(out, (-1,)))\n",
    "        all_labels.append(data.y.float())\n",
    "\n",
    "    # Calculate Metrics\n",
    "    accuracy, f1 = metrics(all_preds, all_labels)\n",
    "\n",
    "    return total_loss / len(test_loader.dataset), accuracy, f1\n",
    "\n",
    "\n",
    "def metrics(preds, gts):\n",
    "    preds = torch.round(torch.cat(preds))\n",
    "    gts = torch.cat(gts)\n",
    "    acc = accuracy_score(preds, gts)\n",
    "    f1 = f1_score(preds, gts)\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(40):\n",
    "    train_loss = train(epoch)\n",
    "    test_loss, test_acc, test_f1 = test(epoch)\n",
    "    print(f'Epoch: {epoch:02d} |  TrainLoss: {train_loss:.2f} | '\n",
    "          f'TestLoss: {test_loss:.2f} | TestAcc: {test_acc:.2f} | TestF1: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in test_loader:\n",
    "    data = data.to(device)\n",
    "    pred = model(data.x, data.edge_index, data.batch)\n",
    "    df = pd.DataFrame()\n",
    "    df[\"pred_logit\"] = pred.detach().numpy()[:,0]\n",
    "    df[\"pred\"] = torch.round(pred).detach().numpy()[:,0]\n",
    "    df[\"true\"] = data.y.numpy()\n",
    "    print(df.head(10))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
